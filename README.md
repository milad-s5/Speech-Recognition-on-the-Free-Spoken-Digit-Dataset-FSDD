
<h1 align="center">
Spoken Digit Recognition Dataset</h1>

<h4 align="center">
    Spoken Digit Recognition with Machine learning methods
</h4>

## Dataset: Free Spoken Digit Dataset (FSDD)

A simple audio/speech dataset consisting of recordings of spoken digits in `wav` files at **8kHz**. The recordings are trimmed so that they have near minimal silence at the beginnings and ends.

FSDD is an open dataset, which means it will grow overtime as data is contributed. Thus in order to enable reproducibility and accurate citation in scientific journals the dataset is versioned using `git tags`. 

## Model and Training
![image](https://user-images.githubusercontent.com/82322980/201336822-d300b2ef-0da3-4a5b-a5aa-948e5cb2206a.png)

The `Notebook.ipynb` consists of:

- Phase_1: Preprocessing
- Phase_2a: Supervised Learning without extracting features
- Phase_2b: Supervised Learning with extracting features
- Phase_3: Unsupervised Learning
